# Agent Maker V2 - Forensic Audit Remediation Plan

**Date**: 2025-11-27 (Updated v2)
**Generated By**: Claude Code (Intent Analyzer + Prompt Architect + Code Validation)
**Source**:
- 8 Phase Forensic Audits (2025-11-27)
- Gemini Audit Report (2025-11-27)
- Comprehensive Forensic Audit (2025-11-26) - ISS-001 to ISS-012
- Phase 5 Detailed Forensic Audit (2025-11-27) - 518 lines
- Remediation Summary (2025-11-26) - Claims fixes, but issues persist
**Validation**: Compared against actual src/ code structure

---

## Executive Summary

### BLOCKING ISSUES (From Gemini Audit - Fix Day 1)

| Issue | Severity | Files Affected | Fix Time |
|-------|----------|----------------|----------|
| `torch.load` without `weights_only=True` | **HIGH (Security)** | 5 files | 1 hour |
| Broken test imports (cross_phase.utils) | MEDIUM | 1 file | 30 min |
| Missing METRICS_COUNT export | MEDIUM | 1 file | 15 min |
| Phase 5 API calls completely mocked | HIGH | 1 file | (in Phase 5 work) |

### Phase Completion Status

| Phase | Current | Target | Gap | Priority | Effort |
|-------|---------|--------|-----|----------|--------|
| Phase 6 (Baking) | 62% | 90% | 28% | **CRITICAL** | 4-5 weeks |
| Phase 1 (Cognate) | 65% | 90% | 25% | **CRITICAL** | 3-4 weeks |
| Phase 5 (Curriculum) | 70% | 90% | 20% | HIGH | 6-8 weeks |
| Phase 7 (Experts) | 75% | 90% | 15% | HIGH | 5-7 weeks |
| Phase 8 (Compression) | 75% | 90% | 15% | MEDIUM | 3-4 weeks |
| Phase 4 (BitNet) | 84.5% | 90% | 5.5% | MEDIUM | 2-3 weeks |
| Phase 2 (EvoMerge) | 87% | 92% | 5% | LOW | 2 weeks |
| Phase 3 (Quiet-STaR) | 91% | 95% | 4% | LOW | 1-2 weeks |

**Total Estimated Effort**: 12-16 weeks (parallelized)
**Estimated API Cost**: $750-1,050 (OpenRouter for Phases 5, 7)

---

## Code Validation Summary

Validated against actual `src/` structure on 2025-11-27:

| Phase | Files | LOC Est. | Tests | E2E Pass |
|-------|-------|----------|-------|----------|
| phase1_cognate | 25 | ~3,000 | 14/14 | YES |
| phase2_evomerge | 22 | ~2,500 | 13/13 | YES |
| phase3_quietstar | 18 | ~5,800 | 16/16 | YES |
| phase4_bitnet | 8 | ~2,200 | Pass | YES |
| phase5_curriculum | 12 | ~1,500 | Pass | YES (1 skip) |
| phase6_baking | 6 | ~800 | Pass | YES |
| phase7_experts | 12 | ~1,200 | Pass | YES |
| phase8_compression | 5 | ~600 | Pass | YES |

**Test Status**: 145 tests, 143 passed, 2 skipped (98.6% pass rate)

---

## TIER 0: IMMEDIATE (Security & Infrastructure)

> **Source**: Gemini Audit Report 2025-11-27

### SECURITY: Unsafe Model Loading (HIGH SEVERITY)

**Finding**: `torch.load` used without `weights_only=True` in **11+ locations** - **arbitrary code execution risk** from malicious checkpoints.

> **DISCREPANCY ALERT**: REMEDIATION-SUMMARY-2025-11-26.md claims ISS-004 FIXED, but Gemini audit (2025-11-27) found issues persist. Verify actual file state.

**Full Affected Files** (from Comprehensive Audit):

| File | Line(s) | Source |
|------|---------|--------|
| `src/phase1_cognate/training/trainer.py` | 442, 464 | Comprehensive Audit |
| `src/phase3_quietstar/step2_rl.py` | 486, 678 | Both audits |
| `src/phase3_quietstar/step1_baking.py` | 471 | Comprehensive Audit |
| `src/phase3_quietstar/phase_handoff.py` | 54, 55, 128, 130, 155, 158, 168, 172 | Both audits |
| `src/phase4_bitnet/phase_controller.py` | 351, 366 | Comprehensive Audit |
| `src/phase4_bitnet/fine_tuner.py` | 442 | Gemini Audit |
| `src/cross_phase/utils/checkpoint_utils.py` | 102 | Gemini Audit |
| `examples/phase3_step1_example.py` | 60 | Comprehensive Audit |
| `examples/phase3_step2_example.py` | 65, 141 | Comprehensive Audit |
| `scripts/validate_phase4.py` | 182, 200, 350, 356 | Comprehensive Audit |
| `scripts/test_phase1_models.py` | 33 | Comprehensive Audit |

**Remediation** (1 hour):
```python
# BEFORE (VULNERABLE):
checkpoint = torch.load(path, map_location=device, weights_only=False)

# AFTER (SECURE):
checkpoint = torch.load(path, map_location=device, weights_only=True)

# OR migrate to safetensors:
from safetensors.torch import load_file
checkpoint = load_file(path)
```

**Success Criteria**:
- [ ] All 5 `torch.load` calls use `weights_only=True`
- [ ] OR migrate to `safetensors` format entirely

---

### INFRASTRUCTURE: Broken Test Imports (MEDIUM SEVERITY)

**Finding**: `tests/unit/test_utils.py` imports fail - `cross_phase.utils` doesn't export required functions.

**Current `src/cross_phase/utils/__init__.py` exports**:
```python
__all__ = ["save_checkpoint", "load_checkpoint", "SAFETENSORS_AVAILABLE", "MockTokenizer", "get_tokenizer"]
```

**Missing exports** (test_utils.py tries to import):
- `get_model_size`
- `calculate_safe_batch_size`
- Other utility functions

**Remediation** (30 minutes):
```python
# MODIFY src/cross_phase/utils/__init__.py
from .utils import get_model_size, calculate_safe_batch_size, ...

__all__ = [
    "save_checkpoint", "load_checkpoint", "SAFETENSORS_AVAILABLE",
    "MockTokenizer", "get_tokenizer",
    # ADD MISSING:
    "get_model_size", "calculate_safe_batch_size", ...
]
```

**Success Criteria**:
- [ ] `pytest tests/unit/test_utils.py` passes collection
- [ ] All utility functions properly exported

---

### INFRASTRUCTURE: WandB Import Issues (MEDIUM SEVERITY)

**Finding**: `src/cross_phase/monitoring/__init__.py` doesn't export `METRICS_COUNT`.

**Remediation** (15 minutes):
```python
# MODIFY src/cross_phase/monitoring/__init__.py
from .metrics import METRICS_COUNT

__all__ = [..., "METRICS_COUNT"]
```

**Success Criteria**:
- [ ] `from cross_phase.monitoring import METRICS_COUNT` works

---

### Phase 5: Mocked API Calls CONFIRMED (HIGH SEVERITY)

**Finding**: `AdaptiveCurriculumGenerator._request_from_api()` is structurally mocked.

**Location**: `src/phase5_curriculum/curriculum_generator.py`

**Current Code**:
```python
def _request_from_api(self, ...):
    # Placeholder - would call actual API
    # ... code commented out ...
    return self._generate_placeholder(model_name, difficulty, level, count)
```

**Implication**:
- "Adaptive Curriculum" is NOT adaptive
- Uses static templates ("Write a function to check if a number is prime")
- "75% edge of chaos" assessment is SIMULATED

**This confirms the Phase 5 (70%) audit finding - the gap is worse than documented.**

---

## TIER 1: CRITICAL (Fix First)

### Phase 6: Baking (62% -> 90%)

**Location**: `src/phase6_baking/` (6 files)

**Current State**:
- A/B cycle orchestration works
- Half-baking interpolation correct
- Plateau detection with adaptive thresholds

**Critical Gaps**:

| Gap | File to Create/Modify | Severity | Effort |
|-----|----------------------|----------|--------|
| KL Divergence Loss | `loss_functions.py` (NEW) | CRITICAL | 3 days |
| Real SWE-Bench | `swe_bench_eval.py` (NEW) | CRITICAL | 1 week |
| True Self-Discovery | `b_cycle_persona.py` (MODIFY) | CRITICAL | 4 days |
| Real Benchmarks | `benchmarks.py` (NEW) | HIGH | 1 week |
| Fix LR (1e-4 -> 5e-5) | `baking_engine.py` (MODIFY) | MEDIUM | 1 hour |

**Detailed Tasks**:

1. **Implement KL Divergence Loss** (Paper Core Objective)
   ```python
   # ADD to src/phase6_baking/loss_functions.py
   def kl_divergence_loss(p_theta_u, p_theta, temperature=1.0):
       """
       KL(P_theta(.|u) || P_theta_u(.))
       Paper Eq 2: theta_u = argmin D_KL(...)
       """
       # Implementation needed
   ```
   - Currently uses cross-entropy only
   - Paper shows KL is core innovation
   - Impact: Enables true prompt baking behavior

2. **Integrate Real SWE-Bench** (A-Cycle Evaluation)
   ```python
   # ADD to src/phase6_baking/swe_bench_eval.py
   class SWEBenchEvaluator:
       """Real GitHub issue resolution tasks"""
       def __init__(self, subset="lite"):  # lite=300, full=2294
       def evaluate(self, model) -> SWEBenchResult:
   ```
   - Currently uses 5 toy tasks
   - Need: SWE-Bench Lite (300 tasks minimum)
   - Cost: Compute time, no API cost

3. **True Self-Discovery** (B-Cycle)
   ```python
   # MODIFY src/phase6_baking/b_cycle_persona.py
   # Current: Extracts from keyword list (fake)
   # Target: Model generates prompts via introspection

   def generate_self_prompts(model, num_prompts=10):
       """Model introspects to discover own patterns"""
       # Use frontier model to analyze base model behavior
       # Generate persona prompts from discovered patterns
   ```
   - Currently hardcoded prompts
   - Need: Model-driven prompt generation
   - Dependency: OpenRouter client ($50-100)

**Success Criteria**:
- [ ] KL divergence loss integrated into training loop
- [ ] SWE-Bench Lite (300+ tasks) running in A-cycle
- [ ] B-cycle generates prompts from model introspection
- [ ] MMLU, GSM8K benchmarks validate quality retention

---

### Phase 1: Cognate (65% -> 90%)

**Location**: `src/phase1_cognate/` (25 files)

**Current State**:
- TRM x Titans-MAG architecture implemented
- ACT Head, LTM Module, MAG Gate all present
- 14/14 E2E tests passing

**Critical Gaps**:

| Gap | File to Modify | Severity | Effort |
|-----|----------------|----------|--------|
| Re-enable Deep Supervision | `training/trainer.py` | CRITICAL | 2 days |
| Add EMA Weight Averaging | `training/trainer.py` | HIGH | 1 day |
| Unit Tests (0% -> 85%) | `tests/unit/test_phase1_*.py` | HIGH | 1 week |
| Surprise-Based Memory | `model/components/memory.py` | MEDIUM | 3 days |
| Adaptive Forgetting | `model/components/memory.py` | MEDIUM | 2 days |

**Detailed Tasks**:

1. **Re-enable Deep Supervision**
   ```python
   # MODIFY src/phase1_cognate/training/trainer.py
   # Current: deep_supervision=False (disabled due to graph reuse)
   # Target: deep_supervision=True with proper gradient handling

   # Fix: Use torch.no_grad() + clone() before reusing features
   def forward_with_deep_supervision(self, x):
       outputs = []
       for step in range(self.T_max):
           # Clone features before reuse to avoid graph errors
           features = self.backbone(x).clone()
           outputs.append(self.head(features))
       return outputs
   ```
   - Paper: N_sup=16 deep supervision steps
   - Currently disabled, missing multi-step gradient flow

2. **Implement EMA Weight Averaging**
   ```python
   # ADD to src/phase1_cognate/training/trainer.py
   class EMAModel:
       """Exponential Moving Average of model weights (Paper: 0.999)"""
       def __init__(self, model, decay=0.999):
           self.shadow = {k: v.clone() for k, v in model.state_dict().items()}

       def update(self, model):
           for k, v in model.state_dict().items():
               self.shadow[k] = self.decay * self.shadow[k] + (1 - self.decay) * v
   ```
   - Paper requires EMA for stability
   - Not implemented anywhere in codebase

3. **Add Unit Tests**
   - Target files needed:
     - `tests/unit/test_phase1_model.py` (model components)
     - `tests/unit/test_phase1_memory.py` (LTM module)
     - `tests/unit/test_phase1_attention.py` (sliding window)
     - `tests/unit/test_phase1_training.py` (trainer)
   - Target coverage: 85%+

**Success Criteria**:
- [ ] Deep supervision enabled without graph errors
- [ ] EMA weight averaging at 0.999 momentum
- [ ] Unit test coverage >= 85%
- [ ] ACT halting variance > 0 (currently 0)

---

## TIER 2: HIGH PRIORITY

### Phase 5: Curriculum (70% -> 90%)

**Location**: `src/phase5_curriculum/` (12 files)

> **Source**: PHASE5_FORENSIC_AUDIT_REPORT.md (518 lines, very detailed)

**Feature Completeness** (from Detailed Audit):

| Feature | Status | Notes |
|---------|--------|-------|
| Stage 1: Assessment | PARTIAL | Uses simulated success rates, not real validation |
| Stage 2: Curriculum Generation | PARTIAL | Placeholder templates, no real frontier API |
| Stage 3: Training Loop | PARTIAL | Core loop works but validation is simulated |
| Stage 3a: Variant Generation | BASIC | Simple text substitution, no frontier model |
| Stage 3b: Hint Generation | BASIC | Template hints, no root cause analysis |
| Stage 3c: Dataset Shrinkage | **WORKING** | Removal after 3 consecutive successes |
| Stage 4: Prompt Baking | DEPENDS | Calls external prompt_baking module |
| Stage 4a: Eudaimonia System | **PLACEHOLDER** | Generic rules, NOT the documented 4-rule/3-archetype system |
| Stage 4b: OODA Loop | **PLACEHOLDER** | Generic OODA, not user-specified 3 parts |
| Stage 4c: Identity Baking | **WORKING** | Specialization-specific prompts |
| Stage 5: Self-Modeling | **WORKING** | Complete temperature range training |
| Stage 6: Dream Consolidation | **WORKING** | Full high-temp replay implementation |
| Stage 7: Level Progression | **WORKING** | 10-level loop with metrics tracking |
| Frontier Model Integration | **MISSING** | OpenRouter API client not implemented |
| Coding Sandbox Environment | **MISSING** | Docker sandbox not implemented |
| W&B Metrics Logging | **MISSING** | 7,200+ metrics not integrated |
| TRM Architecture Integration | **MISSING** | Phase 1 model reuse not implemented |

**Summary**: 7/17 working (41%), 7/17 partial (41%), 3/17 missing (18%)

**Critical Gap: Eudaimonia System**

The documented 4-rule/3-archetype/OODA system is NOT implemented:

```python
# CURRENT (curriculum_engine.py lines 346-352) - PLACEHOLDER:
eudaimonia_prompt = """You are guided by these four principles:
1. Seek to understand before acting
2. Consider consequences for all affected parties
3. Be truthful and transparent in your reasoning
4. Continuously learn and improve
```

**SHOULD BE** (from 589-line PHASE5_EUDAIMONIA_SYSTEM.md):
- **4 Hierarchical Rules**: Eudaimonia Prime Directive, Curiosity as Virtue, Esprit de Corps, Life Value
- **3 Archetypes**: Christ (empathy), Buddha/Lao Tzu (harmony), Stoic (humility)
- **OODA Loop**: Smallest measurable action when eudaimonia <65%

**Gaps to Address**:

| Gap | Status | Effort | Cost |
|-----|--------|--------|------|
| OpenRouter API Client | **MISSING** | 1-2 weeks | $600-800 |
| Docker Coding Sandbox | **MISSING** | 2-3 weeks | $0 |
| W&B Integration (7,200+ metrics) | **MISSING** | 1 week | $0 |
| Eudaimonia System (real) | **PLACEHOLDER** | 1 week | $0 |
| Real Assessment | SIMULATED | 1 week | $100-200 |
| TRM Architecture Reuse | **MISSING** | 2-3 weeks | $0 |

**What's Actually Working**:
- Self-modeling (Stage 5) - temperature range training COMPLETE
- Dream consolidation (Stage 6) - high-temp replay COMPLETE
- Level progression (Stage 7) - 10-level loop WORKING
- Dataset shrinkage - removal after 3 successes WORKING
- Temperature range formulas - PERFECT implementation

**Success Criteria**:
- [ ] OpenRouter client with 4 frontier models
- [ ] Docker sandbox for code execution
- [ ] W&B logging 7,200+ metrics
- [ ] Real Eudaimonia system (4-rule/3-archetype/OODA)
- [ ] Real model assessment replacing simulated
- [ ] TRM architecture integration from Phase 1

---

### Phase 7: Experts (75% -> 90%)

**Location**: `src/phase7_experts/` (12 files)

**Gaps to Address**:

| Gap | File | Effort | Cost |
|-----|------|--------|------|
| REINFORCE for SVF | `svf_trainer.py` | 1 week | $0 |
| Transformer2 Two-Pass | `svf_trainer.py` | 4 days | $0 |
| Expert Composition | `experts_engine.py` | 3 days | $0 |
| Z-Vector Learning | `svf_trainer.py` | 2 days | $0 |
| OpenRouter Integration | NEW FILE | 1 week | $150-250 |
| W&B (350+ metrics) | `wandb_logger.py` | 2 days | $0 |

**Key Implementation**:
```python
# MODIFY src/phase7_experts/svf_trainer.py
class SVFTrainer:
    def train_reinforce(self, expert_configs):
        """
        Transformer2 paper: REINFORCE with two-pass inference

        Pass 1: Generate expert weightings z_1...z_n
        Pass 2: Apply composition W = sum(z_i * W_i)

        Reward: Task accuracy improvement
        """
        # CURRENT: simplified training loop
        # NEEDED: Full REINFORCE with z-vector learning
```

**Success Criteria**:
- [ ] REINFORCE optimization functional
- [ ] Two-pass inference implemented
- [ ] Expert composition working
- [ ] 350+ W&B metrics logging

---

### Phase 8: Compression (75% -> 90%)

**Location**: `src/phase8_compression/` (5 files)

**Gaps to Address**:

| Gap | File | Effort |
|-----|------|--------|
| Complete Hypercompression Curves | `hypercompression.py` | 3 days |
| Grokfast Optimizer Integration | `compression_engine.py` | 2 days |
| Benchmark Testing (MMLU, GSM8K) | NEW `benchmarks.py` | 1 week |
| W&B Logging | NEW `wandb_logger.py` | 1 day |
| Product Quantization Residuals | `vptq.py` | 3 days |

**Key Implementation**:
```python
# MODIFY src/phase8_compression/hypercompression.py
class HyperCompressor:
    def fit_curve(self, weights, curve_type="bezier"):
        """
        Current: Framework only, fitting incomplete
        Target: Full Bezier/polynomial curve fitting
        """
        if curve_type == "bezier":
            return self._fit_bezier(weights)  # NEEDS IMPLEMENTATION
        elif curve_type == "polynomial":
            return self._fit_polynomial(weights)  # NEEDS IMPLEMENTATION
```

**Success Criteria**:
- [ ] Hypercompression achieving 6.25x target
- [ ] Cumulative compression 250-280x
- [ ] Quality retention >= 84%
- [ ] Benchmark validation passing

---

## TIER 3: MEDIUM PRIORITY

### Phase 4: BitNet (84.5% -> 90%)

**Location**: `src/phase4_bitnet/` (8 files)

**Gaps to Address**:

| Gap | File | Effort |
|-----|------|--------|
| Validate Gradient Flow | `phase_controller.py` | 1 day |
| Benchmark Inference Speedup | NEW `benchmark.py` | 3 days |
| Validate Perplexity Formula | `utils.py` | 1 day |
| Complete Integration Tests | `tests/integration/` | 2 days |

**Success Criteria**:
- [ ] Gradient flow validated end-to-end
- [ ] 2-4x inference speedup empirically confirmed
- [ ] Perplexity calculation validated

---

## TIER 4: LOW PRIORITY (Polish)

### Phase 2: EvoMerge (87% -> 92%)

**Nice-to-Have**:
- Scaling Matrix W (paper shows 20% improvement)
- CMA-ES algorithm upgrade (from elite-loser)
- Multi-objective optimization (NSGA-II)

### Phase 3: Quiet-STaR (91% -> 95%)

**Nice-to-Have**:
- Teacher Forcing (n_true=4-12 tokens ahead)
- Meta-Token 100x Gradient Scaling
- Diagonal Attention Mask optimization
- REINFORCE Temperature T=3

---

## Execution Order

### Day 1: TIER 0 - Security & Infrastructure (IMMEDIATE)
```
[SEQUENTIAL - BLOCKING]
|- SECURITY: Fix all 5 torch.load vulnerabilities (1 hour)
|- INFRA: Fix cross_phase.utils exports (30 min)
|- INFRA: Fix cross_phase.monitoring exports (15 min)
|- VERIFY: Run pytest to confirm test collection works
```

**DO NOT proceed to TIER 1 until TIER 0 is complete.**

### Week 1-2: Critical Foundations
```
[PARALLEL]
|- Phase 6: KL Divergence Loss
|- Phase 1: Re-enable Deep Supervision
|- Phase 1: Add EMA Weight Averaging
```

### Week 3-4: Critical Features
```
[PARALLEL]
|- Phase 6: SWE-Bench Integration
|- Phase 6: True Self-Discovery
|- Phase 1: Unit Tests (batch 1)
```

### Week 5-6: High Priority Start
```
[PARALLEL]
|- Phase 5: OpenRouter Client
|- Phase 7: REINFORCE Implementation
|- Phase 8: Hypercompression Curves
```

### Week 7-8: High Priority Continue
```
[PARALLEL]
|- Phase 5: Docker Sandbox + W&B
|- Phase 7: Two-Pass Inference
|- Phase 8: Benchmark Testing
```

### Week 9-10: Integration
```
[PARALLEL]
|- Phase 4: Validation + Benchmarks
|- Cross-phase: Unit Test Coverage
|- Integration Testing
```

### Week 11-12: Polish
```
|- Phase 2: Scaling Matrix W (optional)
|- Phase 3: Teacher Forcing (optional)
|- Documentation Updates
|- Final Validation
```

---

## Comprehensive Issue Tracker (ISS-001 to ISS-012)

> **Source**: AUDIT-REPORT-2025-11-26.md + REMEDIATION-SUMMARY-2025-11-26.md
> **WARNING**: Remediation claims FIXED, but Gemini audit found issues persist

| Issue ID | Description | Claimed Status | Verify |
|----------|-------------|----------------|--------|
| ISS-001 | Fix test_utils.py import error | FIXED | RE-VERIFY |
| ISS-002 | Fix test_wandb_integration.py import | FIXED | RE-VERIFY |
| ISS-003 | Update MuGrokConfig tests | FIXED | RE-VERIFY |
| ISS-004 | Add weights_only=True to torch.load | FIXED | **FAILED** (Gemini found) |
| ISS-005 | Fix Phase 3 architecture tests | FIXED | RE-VERIFY |
| ISS-006 | Remove duplicate MockTokenizer | FIXED | OK |
| ISS-007 | Implement full RL training | FIXED | OK (ISS-007 doc confirms) |
| ISS-008 | Implement STE fine-tuning | FIXED | OK (ISS-008 doc confirms) |
| ISS-009 | Add unit tests for Phase 5 | FIXED | OK |
| ISS-010 | Add unit tests for Phase 6 | FIXED | OK |
| ISS-011 | Add unit tests for Phase 7 | FIXED | OK |
| ISS-012 | Add unit tests for Phase 8 | FIXED | OK |

**Action Required**: Re-verify ISS-001 through ISS-005 as Gemini audit found issues persist.

---

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| **SECURITY: Malicious checkpoints** | Fix torch.load IMMEDIATELY (TIER 0) - 11+ files |
| **Test suite broken** | Fix imports before any other work (TIER 0) |
| **Remediation regression** | Re-verify ISS-001 to ISS-005 before proceeding |
| Breaking working phases (2,3,4) | Feature flags, comprehensive tests before/after |
| API costs exceed budget | Cost caps, checkpoint generation progress |
| SWE-Bench integration complexity | Start with SWE-Bench Lite (300 tasks) |
| Deep supervision graph errors | Proper tensor cloning, gradient checkpointing |
| OpenRouter rate limits | Batch requests, caching, retry logic |
| Phase 5 mocking deeper than expected | Budget extra time, audit all API calls |
| Eudaimonia placeholder | 589-line spec exists, implement properly |

---

## Success Metrics

**Phase Completion Targets**:
- All phases >= 90% complete
- Zero regressions in E2E tests (145/145 pass)
- Unit test coverage >= 85% across all phases
- Documentation accuracy >= 95%

**Quality Gates**:
- Phase 6: KL divergence + real SWE-Bench working
- Phase 1: Deep supervision + EMA enabled
- Phase 5/7: OpenRouter integration operational
- Phase 8: 250x+ compression with 84%+ quality

---

## Budget Summary

| Category | Estimate |
|----------|----------|
| OpenRouter (Phase 5) | $600-800 |
| OpenRouter (Phase 7) | $150-250 |
| **Total API Cost** | **$750-1,050** |
| Compute (local) | $0 |
| **Total** | **$750-1,050** |

---

*Generated: 2025-11-27*
*Methodology: 5-Phase Workflow (Intent -> Prompt -> Plan -> Route -> Execute)*
*Validated Against: Actual src/ code structure*
