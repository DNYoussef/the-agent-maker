# Phase 4: BitNet - 1.58-bit Quantization Configuration
# Compresses model to 1.58-bit using STE (Straight-Through Estimator)

quantization:
  target_bits: 1.58            # Target bits per weight
  method: "bitnet"             # Quantization method
  calibration_samples: 512     # Samples for calibration
  use_ste: true                # Straight-Through Estimator

training:
  num_steps: 2000              # Fine-tuning steps post-quantization
  batch_size: 8
  learning_rate: 1.0e-5
  warmup_steps: 100

validation:
  accuracy_drop_threshold: 0.10   # Max 10% accuracy drop allowed
  perplexity_increase: 2.0        # Max 2x perplexity increase
  compression_target: 6.0         # Minimum 6x compression

mugrokfast:
  enabled: true
  muon_ste_mode: true          # Enable STE compatibility
  grokfast_lambda: 1.5         # Moderate Grokfast filtering

wandb:
  project: "agent-forge-phase4"
  entity: null
  mode: "offline"

checkpoints:
  save_final: true
  dir: "checkpoints/phase4"
